{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Credit Risk Analysis\n",
        "author: Julen Gamboa\n",
        "date: 21 August 2023\n",
        "format:\n",
        "  html:\n",
        "    theme: minty\n",
        "---"
      ],
      "id": "368bd79d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Aim\n",
        "The aim of this analysis is to determine credit risk based on customer behaviour regarding engagement with financial products as well as a variety of demographic attributes that may be informative.\n",
        "\n",
        "It's worth noting that the dataset already contains information about credit risk\n",
        "\n",
        "## Data source\n",
        "\n",
        "In this analysis I'm using a **Kaggle credit risk dataset** described [here](https://www.kaggle.com/datasets/praveengovi/credit-risk-classification-dataset)\n",
        "\n",
        "\n",
        "The data is structured in two csv files:\n",
        "\n",
        ":::{}\n",
        "1. File 1 - **Payment data** contains customer's credit card payment history and has the following fields:\n",
        "- id: customer id\n",
        "- OVD_t1: number of times overdue type 1\n",
        "- OVD_t2: number of times overdue type 2\n",
        "- OVD_t3: number of times overdue type 3\n",
        "- OVD_sum: total overdue days\n",
        "- pay_normal: number of times normal payment\n",
        "- prod_code: credit product code\n",
        "- prod_limit: credit limit of product\n",
        "- update_date: account update date\n",
        "- new_balance: current balance of product\n",
        "- highest_balance: highest balance in history\n",
        "- report_date: date of recent payment\n",
        ":::\n",
        "\n",
        ":::{}\n",
        "2. File 2 - **Customer data** which contains demographic data and category attributes that have been anonymised as follows:\n",
        "- id\n",
        "- label:  if it equals 1 it indicates the customer is high risk, if it equals 0 the customer is low risk\n",
        "- fea_1\n",
        "- fea_2\n",
        "- fea_3\n",
        "- fea_4\n",
        "- fea_5\n",
        "- fea_6\n",
        "- fea_7\n",
        "- fea_8\n",
        "- fea_9\n",
        "- fea_10\n",
        "- fea_11\n",
        ":::\n",
        "\n",
        "## Methodology\n",
        "\n",
        "\n",
        "```{mermaid}\n",
        "flowchart LR\n",
        "  A[Input data] --> B(EDA)\n",
        "  B --> C{Analysis proper}\n",
        "  C --> D[ML methods]\n",
        "  D --> F{Logistic Regression}\n",
        "  D --> G{Naive Bayes}\n",
        "  D --> H{Decision Tree Classifier}\n",
        "  D --> I{XGBoost}\n",
        "  C --> E[Neural Network]\n",
        "  E --> J{Accuracy assessment}\n",
        "  F --> J{Accuracy assessment}\n",
        "  G --> J{Accuracy assessment}\n",
        "  H --> J{Accuracy assessment}\n",
        "  I --> J{Accuracy assessment}\n",
        "  J --> K{Reporting}\n",
        "  K --> L{Select best two methods}\n",
        "  L --> M{Compare common and unique predictions}\n",
        "```\n",
        "\n",
        "\n",
        "### Input data pre-processing"
      ],
      "id": "09e2010f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import KNNImputer\n",
        "import plotnine as p9\n",
        "from plotnine import ggplot, aes, geom_tile, geom_violin, geom_boxplot, geom_label, scale_fill_cmap, scale_fill_gradient, scale_fill_manual, theme_minimal, labs, element_text, facet_wrap\n",
        "import plydata.cat_tools as cat\n",
        "import os\n",
        "\n",
        "# Load the data\n",
        "df1 = pd.read_csv ('~/Desktop/DS/kaggle_projects/Credit_Risk_Classification/data/customer_data.csv')\n",
        "df2 = pd.read_csv ('~/Desktop/DS/kaggle_projects/Credit_Risk_Classification/data/payment_data.csv')\n",
        "\n",
        "# Create a temporary DataFrame for renaming columns\n",
        "df1_renamed = df1.copy()\n",
        "\n",
        "# Rename columns in df1_renamed\n",
        "df1_renamed.columns = df1_renamed.columns.str.replace(r'fea_(\\d+)', r'feature_\\1', regex=True)\n",
        "\n",
        "# Select columns to keep from the original df1\n",
        "columns_to_keep = ['id', 'label']\n",
        "\n",
        "# Select only the renamed feature columns from df1_renamed\n",
        "renamed_feature_columns = df1_renamed.filter(like='feature_')\n",
        "\n",
        "# Concatenate the 'id', 'label', and renamed feature columns\n",
        "df1_final = pd.concat([df1[columns_to_keep], renamed_feature_columns], axis=1)\n",
        "df1_final\n",
        "\n",
        "df1_final.isnull().sum()\n",
        "# we are expencting one with NAs (feature_2)\n",
        "df2.isnull().sum()\n",
        "# For df2 we are expecting NAs on prod_limit and highest balance\n",
        "\n",
        "# Merge df1_final and df2 on id\n",
        "merged_df = df1_final.merge(df2, on='id')\n",
        "\n",
        "# Drop the two columns for which we have no reasonable way of finding out cause for NA\n",
        "merged_df.drop(columns=['update_date','report_date'], inplace=True)\n",
        "\n",
        "# Check NAs (there should be only three features with NAs)\n",
        "merged_df.isnull().sum()\n",
        "\n",
        "# Let's impute those missing values for feature_2, prod_limit, and highest balance\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "impute = KNNImputer(n_neighbors= 5)\n",
        "cols = ['prod_limit','highest_balance','feature_2']\n",
        "merged_df[cols] = merged_df[cols].round()\n",
        "for i in cols:\n",
        "    merged_df[i] = impute.fit_transform(merged_df[[i]])\n",
        "\n",
        "x = merged_df.drop(columns=['label'],axis=1)\n",
        "y = merged_df['label']\n",
        "merged_df.drop(columns=['label'], axis=1, inplace=True)"
      ],
      "id": "0b7d2ac7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Note:\n",
        "After some standard pre-processing (renaming columns, concatenating data frames, and checking for missing data) I decided that data imputation was not appropriate while low credit risk customers might pay their full balance or higher amounts consistently on the same date, high risk customers would exhibit far more variance on both the date of balance closing and last payments made. I personally feel the variable 'pay_normal' (i.e. the number of times a customer does not default on payments) captures this information in a discretised manner that does not rely on following a Poisson distribution of events.\n",
        "\n",
        "In short, I have decided that dropping update_date, and report_date variables was justified. I did however use KNN imputation to fill missing values for feature_2, prod_limit (the credit limit), and highest_balance features, the data for feature 2 appears to be normally distributed, while the prod_limit appears to be close to normally distributed but has a small number of outliers. The highest_balance variable exhibits most values centered close to zero but extremely long tail all the way out  to 150,000,000. \n",
        "\n",
        "##### No missing values present after pre-processing"
      ],
      "id": "a12aa312"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "merged_df.info()"
      ],
      "id": "94239828",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It would be good to visualise how the different variables correlate with one another.\n",
        "\n",
        "*Technical note: The plot was generated with plotnine following Tidyverse principles which I find to be superior to Python libraries*\n"
      ],
      "id": "5373023d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-cap: \"Correlation between different variables in the credit risk customer dataset\"\n",
        "\n",
        "import plotnine as p9\n",
        "from plotnine import aes, geom_tile, geom_label, scale_fill_cmap, theme_minimal, labs, element_text\n",
        "import plydata.cat_tools as cat\n",
        "\n",
        "tidy_corr = merged_df \\\n",
        "    .corr() \\\n",
        "    .melt(\n",
        "        ignore_index=False,\n",
        "    ) \\\n",
        "    .reset_index() \\\n",
        "    .set_axis(\n",
        "        labels = [\"var1\", \"var2\", \"value\"],\n",
        "        axis = 1\n",
        "    ) \\\n",
        "    .assign(lab_text = lambda x: np.round(x['value'], 2)) \\\n",
        "    .assign(\n",
        "        var1 = lambda x: cat.cat_inorder(x['var1']),\n",
        "        var2 = lambda x:\n",
        "             cat.cat_rev(\n",
        "                 cat.cat_inorder(x['var2'])\n",
        "             )\n",
        "    )\n",
        "\n",
        "tidy_corr\n",
        "\n",
        "# Filter tidy_corr to exclude values that are 1.0 or below 0.1\n",
        "tidy_corr_filtered = tidy_corr[(tidy_corr['value'] > 0.1) & (tidy_corr['value'] < 1.0)]\n",
        "\n",
        "(p9.ggplot(\n",
        "    mapping=p9.aes(\"var1\", \"var2\", fill=\"value\"),\n",
        "    data=tidy_corr\n",
        ") +\n",
        "p9.geom_tile(alpha=0.8) +  # Adjust alpha\n",
        "p9.geom_label(\n",
        "    p9.aes(label=\"lab_text\"),\n",
        "    fill=\"white\",\n",
        "    size=8,\n",
        "    data=tidy_corr_filtered  # Apply filter to geom_label\n",
        ") +\n",
        "scale_fill_cmap(name=\"Correlation\", cmap=\"viridis\") +  # Use viridis colormap\n",
        "theme_minimal() +\n",
        "labs(\n",
        "    title=\"Credit Risk | Correlation Matrix Merged Data\",\n",
        "    x=\"\", y=\"\"\n",
        ") +\n",
        "p9.theme(\n",
        "    axis_text_x=element_text(rotation=70, hjust=1),\n",
        "    figure_size=(8, 6)\n",
        "))"
      ],
      "id": "9f4665ec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyses\n",
        "\n",
        "First thing here is to store the label used to classify a customer as high or low credit risk and store it\n",
        "as the response variable for all our models while keeping everything else as our predictor variables\n",
        "\n",
        "\n",
        "### ML methods\n",
        "\n",
        "Four methods will be used, Logistic Regression (LR), Naive Bayes (NB), a Decision Tree Classifier (DT), and XGBoost (XGB).\n",
        "The dataset is split into training and test sets, **70%** is kept for the training set and **30%** will be used as a test set.\n",
        "\n",
        "Hyperparameter tuning was performed for both the DT and XGB models\n",
        "\n",
        "The code is not shown but the prediction accuracy is reported below\n"
      ],
      "id": "abd47f57"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# going for a 30% split\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(x,y, test_size= 0.3)\n",
        "\n",
        "################################\n",
        "##### Logistic Regression ######\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train,Y_train)\n",
        "Y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the accuracy score between prediction and the test data\n",
        "score_lr = round(accuracy_score(Y_pred_lr,Y_test)*100, 2)\n",
        "\n",
        "###############################\n",
        "###### Naive Bayes model ######\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train,Y_train)\n",
        "Y_pred_nb = nb.predict(X_test)\n",
        "\n",
        "\n",
        "# Naive Bayes accuracy score\n",
        "score_nb = round(accuracy_score(Y_pred_nb,Y_test)*100, 2)\n",
        "\n",
        "######################################\n",
        "###### Decision Tree Classifier ######\n",
        "\n",
        "# initialise the max accuracy object for hyperparameter tuning\n",
        "max_accuracy = 0\n",
        "\n",
        "# hyperparameter tuning loop\n",
        "for x in range(200):\n",
        "    dt = DecisionTreeClassifier(random_state=x)\n",
        "    dt.fit(X_train,Y_train)\n",
        "    Y_pred_dt = dt.predict(X_test)\n",
        "    current_accuracy = round(accuracy_score(Y_pred_dt,Y_test)*100, 2)\n",
        "    if(current_accuracy>max_accuracy):\n",
        "        max_accuracy = current_accuracy\n",
        "        best_x = x\n",
        "\n",
        "print(\"Best random state after hyperparameter tuning for the Decision Tree Classifier\") \n",
        "print(best_x)\n",
        "\n",
        "# train the model with the best random state\n",
        "dt = DecisionTreeClassifier(random_state=best_x)\n",
        "dt.fit(X_train,Y_train)\n",
        "Y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "# calculate the accuracy\n",
        "score_dt = round(accuracy_score(Y_pred_dt,Y_test)*100, 2)\n",
        "\n",
        "#####################\n",
        "###### XGBoost XXXXXX\n",
        "\n",
        "# Save the initial XGBoost model\n",
        "import pickle\n",
        "with open('model.pkl', 'wb') as f:\n",
        "    pickle.dump(dt, f)\n",
        "import xgboost as xgb\n",
        "\n",
        "# Initialize the max accuracy object for hyperparameter tuning\n",
        "max_accuracy_xgb = 0\n",
        "\n",
        "# Hyperparameter tuning loop for XGBoost\n",
        "for x in range(200):\n",
        "    xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=x)\n",
        "    xgb_model.fit(X_train, Y_train)\n",
        "    Y_pred_xgb = xgb_model.predict(X_test)\n",
        "    current_accuracy_xgb = round(accuracy_score(Y_pred_xgb, Y_test) * 100, 2)\n",
        "    if current_accuracy_xgb > max_accuracy_xgb:\n",
        "        max_accuracy_xgb = current_accuracy_xgb\n",
        "        best_x_xgb = x\n",
        "\n",
        "print(\"Best random state after hyperparameter tuning for XGBoost\")       \n",
        "print(best_x_xgb)\n",
        "\n",
        "\n",
        "# train the model with the best random state\n",
        "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=0)\n",
        "xgb_model.fit(X_train, Y_train)\n",
        "Y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "\n",
        "# calculate the accuracy\n",
        "score_xgb = round(accuracy_score(Y_pred_xgb,Y_test)*100, 2)\n",
        "\n",
        "# save the trained XGBoost model\n",
        "import pickle\n",
        "with open('model2.pkl', 'wb') as f:\n",
        "    pickle.dump(xgb_model, f)"
      ],
      "id": "e348450c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Accuracy of the ML model predictions"
      ],
      "id": "07695741"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "scores = [score_lr,score_nb,score_dt,score_xgb]\n",
        "algorithms = [\"Logistic Regression\",\"Naive Bayes\",\"Decision Tree\",\"XGBoost\"]    \n",
        "\n",
        "for i in range(len(algorithms)):\n",
        "    print(\"The accuracy score achieved using \"+algorithms[i]+\" is: \"+str(scores[i])+\" %\")"
      ],
      "id": "a6c13657",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Neural Network approach\n",
        "\n",
        "I have used a NN model with a full connected hidden layer containing 11 units and ReLu as activation function. The output layer is configured for binary classification.\n",
        "\n",
        "The model was trained for 3,000 epochs before carrying out predictions on the test set. \n"
      ],
      "id": "6f8a47f2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "# Build the NN model\n",
        "model = Sequential()\n",
        "# 11 units on a fully connected hidden layer, the number of input dimensions is the features in our merged_df\n",
        "model.add(Dense(11, activation='relu', input_dim=21))\n",
        "# output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the NN model\n",
        "# configure loss method for binary classification\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, epochs=3000)\n",
        "\n",
        "# Make predictions on the test data with our trained model\n",
        "Y_pred_nn = model.predict(X_test)"
      ],
      "id": "e5ff1586",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Accuracy of the NN model predictions\n"
      ],
      "id": "63de8464"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "rounded = [round(x[0]) for x in Y_pred_nn]\n",
        "Y_pred_nn = rounded\n",
        "score_nn = round(accuracy_score(Y_pred_nn, Y_test) * 100, 2)\n",
        "print(\"The accuracy score achieved using Neural Network is: \" + str(score_nn) + \" %\")"
      ],
      "id": "4cd11b83",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Reporting the results of our models"
      ],
      "id": "87d1b921"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "from plotnine import ggplot, aes, geom_bar, theme_minimal, labs, scale_fill_cmap\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "\n",
        "scores = [score_lr,score_nb,score_dt,score_xgb,score_nn]\n",
        "algorithms = [\"Logistic Regression\",\"Naive Bayes\",\"Decision Tree\",\"XGBoost\",\"Neural Network\"]    \n",
        "\n",
        "# Define the custom order (I find it is more tasteful to organise the categories according to their\n",
        "# value, it seems to be the default behaviour of bar plots to order categories alphabetically/alphanumerically\n",
        "# regardless of the arguments passed (although in R the forcats library gets around this superbly))\n",
        "custom_order = [\"XGBoost\", \"Decision Tree\", \"Logistic Regression\", \"Neural Network\", \"Naive Bayes\"]\n",
        "\n",
        "# Create a DataFrame for plotting\n",
        "df = pd.DataFrame({\"Algorithm\": algorithms, \"Score\": scores})\n",
        "\n",
        "# Reorder the DataFrame based on the custom order\n",
        "df[\"Algorithm\"] = pd.Categorical(df[\"Algorithm\"], categories=custom_order, ordered=True)\n",
        "df = df.sort_values(\"Algorithm\")\n",
        "# Sort the DataFrame by score in descending order\n",
        "#df = df.sort_values(by=\"Score\", ascending=False)\n",
        "\n",
        "# Assign specified colors to algorithms\n",
        "# I couldn't get this to simply sample 5 colours from viridis and then assign them\n",
        "# to each algorithm rather than assign the colours to the accuracy scores so\n",
        "# if you need to generate more in order to fit say 6 models, here's a resource\n",
        "# for that.\n",
        "# https://waldyrious.net/viridis-palette-generator/\n",
        "\n",
        "colour_dict = {\n",
        "    \"XGBoost\": \"#440154\",\n",
        "    \"Decision Tree\": \"#3b528b\",\n",
        "    \"Logistic Regression\": \"#21918c\",\n",
        "    \"Neural Network\": \"#5ec962\",\n",
        "    \"Naive Bayes\": \"#fde725\"\n",
        "}\n",
        "\n",
        "# Add a new 'Colour' column based on algorithm order\n",
        "df[\"Colour\"] = df[\"Algorithm\"].map(colour_dict)\n",
        "\n",
        "p = (ggplot(df, aes(x=\"Algorithm\", y=\"Score\", fill=\"Colour\"))\n",
        "    + geom_bar(stat=\"identity\")\n",
        "    + theme_minimal()\n",
        "    + labs(title=\"Algorithm Scores\", x=\"Algorithm\", y=\"Accuracy\")\n",
        "    + scale_fill_manual(values=df[\"Colour\"].tolist(), guide=False)\n",
        ")\n",
        "\n",
        "print(p)"
      ],
      "id": "19fd1c8f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Selecting the best methods based on the accuracy scores\n",
        "\n",
        "The reason why one would want to consider selecting the results of more than one method are many. For one, the way a given classifier method might choose a given outcome may be affected by specific statistical quirks of each method, for closely scoring methods one may want to see what predicted IDs are common to both methods and which ones aren't in order to better understand what parameters might be more relevant to each model.\n"
      ],
      "id": "d7c74a6d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Predict labels using XGBoost\n",
        "xgb_predicted_labels = xgb_model.predict(X_test)\n",
        "\n",
        "# Predict labels using Decision Tree\n",
        "dt_predicted_labels = dt.predict(X_test)\n",
        "\n",
        "# Filter rows where XGBoost predicted high credit risk (1)\n",
        "high_risk_cases_xgb = X_test[xgb_predicted_labels == 1]\n",
        "\n",
        "# Filter rows where Decision Tree predicted high credit risk (1)\n",
        "high_risk_cases_dt = X_test[dt_predicted_labels == 1]\n",
        "\n",
        "# Now you have two DataFrames: high_risk_cases_xgb and high_risk_cases_dt\n",
        "# These DataFrames contain cases where the respective models predicted high credit risk.\n",
        "\n",
        "# Concatenate both DataFrames vertically\n",
        "common_high_risk_cases = pd.concat([high_risk_cases_xgb, high_risk_cases_dt], ignore_index=True)\n",
        "\n",
        "# Drop duplicates based on the 'id' column\n",
        "common_high_risk_cases = common_high_risk_cases.drop_duplicates(subset='id')\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "#print(common_high_risk_cases)\n",
        "\n",
        "\n",
        "# Create DataFrames to store the IDs that were predicted by one algorithm but not the other\n",
        "xgb_missing_ids = X_test.copy()\n",
        "xgb_missing_ids['model'] = 'xgb'\n",
        "xgb_missing_ids = xgb_missing_ids[~xgb_predicted_labels.astype(bool)]\n",
        "\n",
        "dt_missing_ids = X_test.copy()\n",
        "dt_missing_ids['model'] = 'dt'\n",
        "dt_missing_ids = dt_missing_ids[~dt_predicted_labels.astype(bool)]\n",
        "\n",
        "# Concatenate both DataFrames vertically\n",
        "missing_ids = pd.concat([xgb_missing_ids, dt_missing_ids], ignore_index=True)\n",
        "\n",
        "# Drop duplicates based on the 'id' column\n",
        "missing_ids = missing_ids.drop_duplicates(subset='id')"
      ],
      "id": "80d16d38",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Visualising differences between the predicted customers common to both models and those that are unique to either model\n",
        "\n",
        "##### Plot all high risk cases predicted by both XGBoost and DT models\n"
      ],
      "id": "56eeff8a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import plotnine as p9\n",
        "from plotnine import aes, geom_tile, geom_label, scale_fill_cmap, theme_minimal, labs, element_text\n",
        "import plydata.cat_tools as cat\n",
        "\n",
        "tidy_corr = df_com \\\n",
        "    .corr() \\\n",
        "    .melt(\n",
        "        ignore_index=False,\n",
        "    ) \\\n",
        "    .reset_index() \\\n",
        "    .set_axis(\n",
        "        labels = [\"var1\", \"var2\", \"value\"],\n",
        "        axis = 1\n",
        "    ) \\\n",
        "    .assign(lab_text = lambda x: np.round(x['value'], 2)) \\\n",
        "    .assign(\n",
        "        var1 = lambda x: cat.cat_inorder(x['var1']),\n",
        "        var2 = lambda x:\n",
        "             cat.cat_rev(\n",
        "                 cat.cat_inorder(x['var2'])\n",
        "             )\n",
        "    )\n",
        "\n",
        "tidy_corr\n",
        "\n",
        "# Filter tidy_corr to exclude values that are 1.0 or below 0.1\n",
        "tidy_corr_filtered = tidy_corr[(tidy_corr['value'] > 0.1) & (tidy_corr['value'] < 1.0)]\n",
        "\n",
        "(p9.ggplot(\n",
        "    mapping=p9.aes(\"var1\", \"var2\", fill=\"value\"),\n",
        "    data=tidy_corr\n",
        ") +\n",
        "p9.geom_tile(alpha=0.8) +  # Adjust alpha\n",
        "p9.geom_label(\n",
        "    p9.aes(label=\"lab_text\"),\n",
        "    fill=\"white\",\n",
        "    size=8,\n",
        "    data=tidy_corr_filtered  # Apply filter to geom_label\n",
        ") +\n",
        "scale_fill_cmap(name=\"Correlation\", cmap=\"viridis\") +  # Use viridis colormap\n",
        "theme_minimal() +\n",
        "labs(\n",
        "    title=\"Correlation Matrix ML predicted high risk cases\",\n",
        "    x=\"\", y=\"\"\n",
        ") +\n",
        "p9.theme(\n",
        "    axis_text_x=element_text(rotation=70, hjust=1),\n",
        "    figure_size=(8, 6)\n",
        ")) "
      ],
      "id": "e84f63d3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### And those predicted by XGBoost but not the Decision Tree Classifier model\n"
      ],
      "id": "13918d48"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Now the missing cases for the DT model (i.e. the ones predicted by XGBoost but not DT)\n",
        "\n",
        "tidy_corr = df_mis_dt \\\n",
        "    .corr() \\\n",
        "    .melt(\n",
        "        ignore_index=False,\n",
        "    ) \\\n",
        "    .reset_index() \\\n",
        "    .set_axis(\n",
        "        labels = [\"var1\", \"var2\", \"value\"],\n",
        "        axis = 1\n",
        "    ) \\\n",
        "    .assign(lab_text = lambda x: np.round(x['value'], 2)) \\\n",
        "    .assign(\n",
        "        var1 = lambda x: cat.cat_inorder(x['var1']),\n",
        "        var2 = lambda x:\n",
        "             cat.cat_rev(\n",
        "                 cat.cat_inorder(x['var2'])\n",
        "             )\n",
        "    )\n",
        "\n",
        "tidy_corr\n",
        "\n",
        "# Filter tidy_corr to exclude values that are 1.0 or below 0.1\n",
        "tidy_corr_filtered = tidy_corr[(tidy_corr['value'] > 0.1) & (tidy_corr['value'] < 1.0)]\n",
        "\n",
        "(p9.ggplot(\n",
        "    mapping=p9.aes(\"var1\", \"var2\", fill=\"value\"),\n",
        "    data=tidy_corr\n",
        ") +\n",
        "p9.geom_tile(alpha=0.8) +  # Adjust alpha\n",
        "p9.geom_label(\n",
        "    p9.aes(label=\"lab_text\"),\n",
        "    fill=\"white\",\n",
        "    size=8,\n",
        "    data=tidy_corr_filtered  # Apply filter to geom_label\n",
        ") +\n",
        "scale_fill_cmap(name=\"Correlation\", cmap=\"viridis\") +  # Use viridis colormap\n",
        "theme_minimal() +\n",
        "labs(\n",
        "    title=\"Correlation Matrix XGBoost unique high risk cases\",\n",
        "    x=\"\", y=\"\"\n",
        ") +\n",
        "p9.theme(\n",
        "    axis_text_x=element_text(rotation=70, hjust=1),\n",
        "    figure_size=(8, 6)\n",
        ")) "
      ],
      "id": "6e157876",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Finally those predictions made by the Decision Tree Classifier model but not XGBoost"
      ],
      "id": "00ada79b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# And for those predicted by DT but not XGBoost\n",
        "tidy_corr = df_mis_xgb \\\n",
        "    .corr() \\\n",
        "    .melt(\n",
        "        ignore_index=False,\n",
        "    ) \\\n",
        "    .reset_index() \\\n",
        "    .set_axis(\n",
        "        labels = [\"var1\", \"var2\", \"value\"],\n",
        "        axis = 1\n",
        "    ) \\\n",
        "    .assign(lab_text = lambda x: np.round(x['value'], 2)) \\\n",
        "    .assign(\n",
        "        var1 = lambda x: cat.cat_inorder(x['var1']),\n",
        "        var2 = lambda x:\n",
        "             cat.cat_rev(\n",
        "                 cat.cat_inorder(x['var2'])\n",
        "             )\n",
        "    )\n",
        "\n",
        "tidy_corr\n",
        "\n",
        "# Filter tidy_corr to exclude values that are 1.0 or below 0.1\n",
        "tidy_corr_filtered = tidy_corr[(tidy_corr['value'] > 0.1) & (tidy_corr['value'] < 1.0)]\n",
        "\n",
        "(p9.ggplot(\n",
        "    mapping=p9.aes(\"var1\", \"var2\", fill=\"value\"),\n",
        "    data=tidy_corr\n",
        ") +\n",
        "p9.geom_tile(alpha=0.8) +  # Adjust alpha\n",
        "p9.geom_label(\n",
        "    p9.aes(label=\"lab_text\"),\n",
        "    fill=\"white\",\n",
        "    size=8,\n",
        "    data=tidy_corr_filtered  # Apply filter to geom_label\n",
        ") +\n",
        "scale_fill_cmap(name=\"Correlation\", cmap=\"viridis\") +  # Use viridis colormap\n",
        "theme_minimal() +\n",
        "labs(\n",
        "    title=\"Correlation Matrix DT unique high risk cases\",\n",
        "    x=\"\", y=\"\"\n",
        ") +\n",
        "p9.theme(\n",
        "    axis_text_x=element_text(rotation=70, hjust=1),\n",
        "    figure_size=(8, 6)\n",
        ")) "
      ],
      "id": "091ab0bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the features that matter to predict high risk are the same for both XGBoost and DT models. However, there are some differences in the correlation values possibly arising from differences in sensitivity between ensemble models (XGBoost) and other classifier models such as decision tree classifiers. Whether the sensitivity threshold in making these predictions should be tweaked or not would depend on how much risk can be tolerated but both models perform well, although XGBoost shows marginally better performance."
      ],
      "id": "454bc03c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}